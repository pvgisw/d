Reducer

import sys
import io

current_word = None
current_count = 0
word = None

for line in sys.stdin:
	word, count = line.split('\t',1)
	count = int(count)
	if current_word==word :
		current_count += count
	else :
		if current_word:
			print("%s\t%s" %(current_word,current_count))
		current_word = word
		current_count = count

if current_word:
	print("%s\t%s" %(current_word,current_count))

















import sys
import io

input_stream = io.TextIOWrapper(sys.stdin.buffer)

for line in input_stream:
	line = line.lower()
	words = line.split()
	for word in words:
		print("%s\t%s" %(word,1))

mapper.py
Displaying mapper.py.



hadoop jar /usr/local/hadoop/share/hadoop/tools/lib/hadoop-streaming-3.3.4.jar -input /pyhadoop/samp.txt 
-output /pyhadoop/count1 -file mapper.py -file reducer.py -mapper 'python3 mapper.py' -reducer 'python3 reducer.py'

